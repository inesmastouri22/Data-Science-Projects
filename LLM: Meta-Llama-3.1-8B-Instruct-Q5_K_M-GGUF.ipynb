{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5200e7-ef16-42dd-badf-ca8b2aed88d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 29 key-value pairs and 291 tensors from C:\\Users\\DELL\\.cache\\lm-studio\\models\\deven367\\Meta-Llama-3.1-8B-Instruct-Q5_K_M-GGUF\\meta-llama-3.1-8b-instruct-q5_k_m.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.1\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 5.33 GiB (5.70 BPW) \n",
      "llm_load_print_meta: general.name     = Meta Llama 3.1 8B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  5459.93 MiB\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'Meta Llama 3.1 8B Instruct', 'general.architecture': 'llama', 'general.type': 'model', 'llama.block_count': '32', 'general.basename': 'Meta-Llama-3.1', 'general.finetune': 'Instruct', 'general.size_label': '8B', 'general.license': 'llama3.1', 'llama.context_length': '131072', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '128009', 'general.file_type': '17', 'llama.attention.head_count_kv': '8', 'llama.rope.freq_base': '500000.000000', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\"}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
      "\n",
      "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /    15 runs   (    0.20 ms per token,  4892.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  137627.33 ms /   616 tokens (  223.42 ms per token,     4.48 tokens per second)\n",
      "llama_print_timings:        eval time =    5390.47 ms /    14 runs   (  385.03 ms per token,     2.60 tokens per second)\n",
      "llama_print_timings:       total time =  143064.90 ms /   630 tokens\n",
      "Llama.generate: 603 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    35 runs   (    0.19 ms per token,  5361.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2117.99 ms /    12 tokens (  176.50 ms per token,     5.67 tokens per second)\n",
      "llama_print_timings:        eval time =    9945.15 ms /    34 runs   (  292.50 ms per token,     3.42 tokens per second)\n",
      "llama_print_timings:       total time =   12167.79 ms /    46 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 214 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Write A Feature Length Screenplay For Film Or Television\n",
      "Prerequisites: `[\"Basic Word Processor\", \"Screenplay Writing Experience (Optional)\"]\n",
      "Learning Outcomes: ['Screenplay Writing', 'Script writing for Film or Television', 'Writing a feature length screenplay', 'Pitching your first script', 'Getting started on your next script']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /    21 runs   (    0.14 ms per token,  7037.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   51852.95 ms /   214 tokens (  242.30 ms per token,     4.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5474.08 ms /    20 runs   (  273.70 ms per token,     3.65 tokens per second)\n",
      "llama_print_timings:       total time =   57370.48 ms /   234 tokens\n",
      "Llama.generate: 205 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    34 runs   (    0.26 ms per token,  3919.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2047.15 ms /    12 tokens (  170.60 ms per token,     5.86 tokens per second)\n",
      "llama_print_timings:        eval time =   17113.16 ms /    33 runs   (  518.58 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =   19288.64 ms /    45 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 432 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Business Strategy: Business Model Canvas Analysis with Miro\n",
      "Prerequisites: ['Python' , 'Excel' , 'Business' , 'project' , 'Financial Analysis']\n",
      "Learning Outcomes: ['Finance', 'Business Plan', 'Persona', 'Business Model Canvas', 'Planning', 'Business', 'Project', 'Product Development', 'Presentation', 'Strategy']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      14.38 ms /    63 runs   (    0.23 ms per token,  4381.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   87241.01 ms /   432 tokens (  201.95 ms per token,     4.95 tokens per second)\n",
      "llama_print_timings:        eval time =   27825.22 ms /    62 runs   (  448.79 ms per token,     2.23 tokens per second)\n",
      "llama_print_timings:       total time =  115282.79 ms /   494 tokens\n",
      "Llama.generate: 423 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      24.57 ms /   100 runs   (    0.25 ms per token,  4070.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2519.62 ms /    12 tokens (  209.97 ms per token,     4.76 tokens per second)\n",
      "llama_print_timings:        eval time =   36757.34 ms /    99 runs   (  371.29 ms per token,     2.69 tokens per second)\n",
      "llama_print_timings:       total time =   39579.62 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 187 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Silicon Thin Film Solar Cells\n",
      "Prerequisites: [\n",
      "    \"Mathematics (Linear Algebra, Differential Equations)\",\n",
      "    \"Physics (Semiconductor Physics, Solid State Physics)\",\n",
      "    \"Chemistry (Inorganic Chemistry, Solid State Chemistry)\",\n",
      "    \"Electrical Engineering (Electronics, Microelectronics)\",\n",
      "    \"Materials Science (Materials Science, Thin Films)\"]\n",
      "Learning Outcomes: [\"Understand the general principles of silicon thin film solar cells\", \"Know the properties of disordered and crystalline semiconductors\", \"Be able to describe the growth mechanisms of silicon thin films\", \"Understand the consequences of semiconductor properties on solar cells behavior\", \"Be able to describe the optical properties of amorphous and nanocrystalline silicon\", \"Understand the advantages of plasma processes in the preparation of multijunctions and heterojunctions solar cells\", \"Know]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    18 runs   (    0.13 ms per token,  7768.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   30485.49 ms /   187 tokens (  163.02 ms per token,     6.13 tokens per second)\n",
      "llama_print_timings:        eval time =    5123.20 ms /    17 runs   (  301.36 ms per token,     3.32 tokens per second)\n",
      "llama_print_timings:       total time =   35644.17 ms /   204 tokens\n",
      "Llama.generate: 178 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      17.72 ms /   100 runs   (    0.18 ms per token,  5642.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2023.29 ms /    12 tokens (  168.61 ms per token,     5.93 tokens per second)\n",
      "llama_print_timings:        eval time =   33761.98 ms /    99 runs   (  341.03 ms per token,     2.93 tokens per second)\n",
      "llama_print_timings:       total time =   36045.68 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 431 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Finance for Managers\n",
      "Prerequisites: [\"Accounting\", \"Finance\", \"Operations Management\", \"Leadership and Management\"]\n",
      "Learning Outcomes: ['Be able to analyze and interpret the income statement and the balance sheet',\n",
      " 'Know how to calculate and explain different financial ratios, including return on equity (ROE), return on assets (ROA), and debt-to-equity (D/E)',\n",
      " 'Understand how to manage working capital, including accounts receivable, inventory, and accounts payable',\n",
      " 'Learn how to use financial statements to make short-term and long-term decisions',\n",
      " 'Be able to calculate and explain the DuPont analysis',\n",
      " ']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    15 runs   (    0.17 ms per token,  5877.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   87825.92 ms /   431 tokens (  203.77 ms per token,     4.91 tokens per second)\n",
      "llama_print_timings:        eval time =    4584.26 ms /    14 runs   (  327.45 ms per token,     3.05 tokens per second)\n",
      "llama_print_timings:       total time =   92444.23 ms /   445 tokens\n",
      "Llama.generate: 422 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    62 runs   (    0.20 ms per token,  5034.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2153.34 ms /    12 tokens (  179.44 ms per token,     5.57 tokens per second)\n",
      "llama_print_timings:        eval time =   21583.78 ms /    61 runs   (  353.83 ms per token,     2.83 tokens per second)\n",
      "llama_print_timings:       total time =   23905.52 ms /    73 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 212 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Retrieve Data using Single-Table SQL Queries\n",
      "Prerequisites: [\"No prior knowledge of SQL or databases is required to take this course\"]\n",
      "Learning Outcomes: [\"Understanding of how to effectively retrieve data from a relational database table using SQL language\", \"Knowledge of SQL syntax and commands\", \"Skills in writing SQL queries using SQLiteStudio\", \"Ability to practice writing SQL queries to retrieve data\", \"Understanding of how to display retrieved data on a web page or PC application\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    47 runs   (    0.14 ms per token,  7098.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   41454.27 ms /   212 tokens (  195.54 ms per token,     5.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12556.70 ms /    46 runs   (  272.97 ms per token,     3.66 tokens per second)\n",
      "llama_print_timings:       total time =   54103.60 ms /   258 tokens\n",
      "Llama.generate: 203 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      21.06 ms /    85 runs   (    0.25 ms per token,  4035.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2297.44 ms /    12 tokens (  191.45 ms per token,     5.22 tokens per second)\n",
      "llama_print_timings:        eval time =   35296.75 ms /    84 runs   (  420.20 ms per token,     2.38 tokens per second)\n",
      "llama_print_timings:       total time =   37886.64 ms /    96 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 160 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Building Test Automation Framework using Selenium and TestNG\n",
      "Prerequisites: [\"Python 3.x\", \"PyCharm\", \"Selenium WebDriver\", \"TestNG\", \"Coursera\", \"TestNG.xml\", \"ExtentReports\", \"ExtentReports.xml\", \"Java\", \"Windows or Linux\"]\n",
      "Learning Outcomes: [\"test automation using selenium and testNG\", \"selenium best practices\", \"testNG best practices\", \"testNG frameworks\", \"testNG annotation\", \"testNG reporting\", \"testNG listeners\", \"selenium IDE\", \"selenium grid\", \"selenium standalone\", \"selenium remote\", \"selenium web driver\", \"selenium API\", \"selenium WebDriverManager\", \"selenium testNG integration\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    14 runs   (    0.17 ms per token,  5887.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   29565.32 ms /   160 tokens (  184.78 ms per token,     5.41 tokens per second)\n",
      "llama_print_timings:        eval time =    4379.67 ms /    13 runs   (  336.90 ms per token,     2.97 tokens per second)\n",
      "llama_print_timings:       total time =   33978.26 ms /   173 tokens\n",
      "Llama.generate: 151 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      20.51 ms /   100 runs   (    0.21 ms per token,  4875.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2173.08 ms /    12 tokens (  181.09 ms per token,     5.52 tokens per second)\n",
      "llama_print_timings:        eval time =   37274.99 ms /    99 runs   (  376.52 ms per token,     2.66 tokens per second)\n",
      "llama_print_timings:       total time =   39759.90 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 462 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Doing Business in China Capstone\n",
      "Prerequisites: [‘Marketing in China’, ‘Doing Business in China’]\n",
      "Learning Outcomes: ```python\n",
      "[\n",
      "    {\"name\": \"Analyze the Chinese market and identify potential opportunities for a new overseas product.\", \"weightage\": 30},\n",
      "    {\"name\": \"Develop a marketing plan to introduce the new overseas product to the Chinese market.\", \"weightage\": 25},\n",
      "    {\"name\": \"Create a detailed business plan, including market research, financial projections, and operational strategies.\", \"weightage\": 20},\n",
      "    {\"name\": \"Evaluate the feasibility of bringing the new]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     8 runs   (    0.18 ms per token,  5693.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   92091.52 ms /   462 tokens (  199.33 ms per token,     5.02 tokens per second)\n",
      "llama_print_timings:        eval time =    2722.07 ms /     7 runs   (  388.87 ms per token,     2.57 tokens per second)\n",
      "llama_print_timings:       total time =   94834.74 ms /   469 tokens\n",
      "Llama.generate: 453 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    32 runs   (    0.14 ms per token,  7248.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2857.88 ms /    12 tokens (  238.16 ms per token,     4.20 tokens per second)\n",
      "llama_print_timings:        eval time =    7672.60 ms /    31 runs   (  247.50 ms per token,     4.04 tokens per second)\n",
      "llama_print_timings:       total time =   10592.41 ms /    43 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 501 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Programming Languages, Part A\n",
      "Prerequisites: ['Math', 'CS 112']\n",
      "Learning Outcomes: [\"inference\", \"ml\", \"higher-order function\", \"functional programming\", \"type inference\", \"pattern matching\", \"euler's totient function\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    27 runs   (    0.13 ms per token,  7674.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   96746.45 ms /   501 tokens (  193.11 ms per token,     5.18 tokens per second)\n",
      "llama_print_timings:        eval time =    6328.43 ms /    26 runs   (  243.40 ms per token,     4.11 tokens per second)\n",
      "llama_print_timings:       total time =  103124.92 ms /   527 tokens\n",
      "Llama.generate: 492 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      23.03 ms /   100 runs   (    0.23 ms per token,  4342.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.37 ms /    12 tokens (  117.86 ms per token,     8.48 tokens per second)\n",
      "llama_print_timings:        eval time =   38226.75 ms /    99 runs   (  386.13 ms per token,     2.59 tokens per second)\n",
      "llama_print_timings:       total time =   39969.38 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 381 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: The Roles and Responsibilities of Nonprofit Boards of Directors within the Governance Process\n",
      "Prerequisites: ```python\n",
      "prerequisites = [\n",
      "    \"Introduction to Nonprofit Governance\",\n",
      "    \"Introduction to Nonprofit Management and Leadership\"]\n",
      "Learning Outcomes: [ 'Understand the role of a board of directors in a nonprofit organization', 'Recognize the importance of strategic planning in the nonprofit sector', 'Identify the key elements of the resource development process', 'Develop skills in assessing performance and making recommendations for improvement', 'Understand the board's role in ensuring the organization has adequate funding', 'Develop skills in planning and implementing a resource development plan', 'Develop skills in concept testing and measurement', 'Develop skills in peer review and evaluation', 'Under]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    25 runs   (    0.19 ms per token,  5329.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   79042.58 ms /   381 tokens (  207.46 ms per token,     4.82 tokens per second)\n",
      "llama_print_timings:        eval time =    8369.36 ms /    24 runs   (  348.72 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =   87479.83 ms /   405 tokens\n",
      "Llama.generate: 372 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      20.41 ms /   100 runs   (    0.20 ms per token,  4900.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2534.89 ms /    12 tokens (  211.24 ms per token,     4.73 tokens per second)\n",
      "llama_print_timings:        eval time =   34213.49 ms /    99 runs   (  345.59 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =   37040.27 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 211 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Business Russian Communication. Part 3\n",
      "Prerequisites: ['A2 A2 level in Russian', 'grammar of Russian language', 'Russian vocabulary', 'listening and speaking skills']\n",
      "Learning Outcomes: [\"Demonstrate ability to communicate effectively in the Russian language in everyday situations, especially in a business context.\",\n",
      "\"Demonstrate understanding of business-related vocabulary and grammar in the Russian language.\",\n",
      "\"Apply business-related vocabulary and grammar in the Russian language in everyday situations.\",\n",
      "\"Participate in a conversation and engage in a business-related discussion in the Russian language.\",\n",
      "\"Use the correct grammar and vocabulary in a business-related context.\",\n",
      "\"Apply critical thinking and problem-solving skills in a business-related context in the Russian]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       5.00 ms /    26 runs   (    0.19 ms per token,  5203.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =   39376.91 ms /   211 tokens (  186.62 ms per token,     5.36 tokens per second)\n",
      "llama_print_timings:        eval time =    8653.50 ms /    25 runs   (  346.14 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =   48095.49 ms /   236 tokens\n",
      "Llama.generate: 202 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      22.25 ms /   100 runs   (    0.22 ms per token,  4495.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2138.51 ms /    12 tokens (  178.21 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:        eval time =   39942.11 ms /    99 runs   (  403.46 ms per token,     2.48 tokens per second)\n",
      "llama_print_timings:       total time =   42402.07 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 148 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Agile Projects:  Developing Tasks with Taiga\n",
      "Prerequisites: ```python\n",
      "prerequisites = {\n",
      "    \"required_courses\": [\"Agile Projects:  Defining Projects with Taiga\"]\n",
      "Learning Outcomes: [\n",
      "    {\"label\": \"Develop tasks for Agile projects\", \"description\": \"You can identify how the customer user will experience the product or service.\"},\n",
      "    {\"label\": \"Encapsulate value for the customer in tasks\", \"description\": \"You can encapsulate value for the customer in these tasks.\"},\n",
      "    {\"label\": \"Identify the development roadmap of products and services\", \"description\": \"You can identify the development roadmap of products and services.\"},\n",
      "    {\"label\": \"Define how user]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    49 runs   (    0.20 ms per token,  4937.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27530.56 ms /   148 tokens (  186.02 ms per token,     5.38 tokens per second)\n",
      "llama_print_timings:        eval time =   17517.42 ms /    48 runs   (  364.95 ms per token,     2.74 tokens per second)\n",
      "llama_print_timings:       total time =   45189.99 ms /   196 tokens\n",
      "Llama.generate: 139 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      23.58 ms /   100 runs   (    0.24 ms per token,  4240.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3507.68 ms /    12 tokens (  292.31 ms per token,     3.42 tokens per second)\n",
      "llama_print_timings:        eval time =   40761.46 ms /    99 runs   (  411.73 ms per token,     2.43 tokens per second)\n",
      "llama_print_timings:       total time =   44596.66 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 321 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Esports Management Capstone Project\n",
      "Prerequisites: ```python\n",
      "prerequisites = [\n",
      "    \"ESPM 70A\",\n",
      "    \"ESPM 70B\",\n",
      "    \"ESPM 70C\",\n",
      "    \"ESPM 90A\",\n",
      "    \"ESPM 90B\"]\n",
      "Learning Outcomes: ```\n",
      "[\n",
      "    \"Develop a comprehensive understanding of the Esport industry and its business aspects\",\n",
      "    \"Create effective branding strategies for Esport organizations\",\n",
      "    \"Recruit funding resources for a hypothetical Esport organization\",\n",
      "    \"Evaluate the pros and cons of creating a single or multiple Esport organizations\",\n",
      "    \"Develop strong planning and leadership skills to manage an Esport organization\",\n",
      "    \"Analyze and describe the role of interest in the Esport industry\",\n",
      "    \"Develop a peer-reviewing and]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    39 runs   (    0.17 ms per token,  5887.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   61898.06 ms /   321 tokens (  192.83 ms per token,     5.19 tokens per second)\n",
      "llama_print_timings:        eval time =   11746.42 ms /    38 runs   (  309.12 ms per token,     3.24 tokens per second)\n",
      "llama_print_timings:       total time =   73739.22 ms /   359 tokens\n",
      "Llama.generate: 312 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      23.84 ms /   100 runs   (    0.24 ms per token,  4194.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2212.41 ms /    12 tokens (  184.37 ms per token,     5.42 tokens per second)\n",
      "llama_print_timings:        eval time =   40727.00 ms /    99 runs   (  411.38 ms per token,     2.43 tokens per second)\n",
      "llama_print_timings:       total time =   43261.48 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 201 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Hacking and Patching\n",
      "Prerequisites: ```\n",
      "prerequisites = [\"Basic Linux usage\", \"Python Programming\", \"HTML & CSS\", \"JavaScript\", \"SQL\", \"Web Application Security\", \"SQL Injection\", \"Input Validation\"]\n",
      "Learning Outcomes: ```python\n",
      "learning_outcomes = [\n",
      "    \"You will be able to find command injection vulnerabilities on web apps with input validation using regular expressions\",\n",
      "    \"You will be able to hack web apps with SQL injection vulnerabilities to retrieve user profile information and passwords\",\n",
      "    \"You will be able to patch web apps with input validation and SQL parameter binding to prevent SQL injection attacks\",\n",
      "    \"You will be able to understand the hacking methodology and use tools like Nessus, Kali Linux, and Metasp]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /    24 runs   (    0.13 ms per token,  7920.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   40976.35 ms /   201 tokens (  203.86 ms per token,     4.91 tokens per second)\n",
      "llama_print_timings:        eval time =    5565.08 ms /    23 runs   (  241.96 ms per token,     4.13 tokens per second)\n",
      "llama_print_timings:       total time =   46585.48 ms /   224 tokens\n",
      "Llama.generate: 192 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    41 runs   (    0.24 ms per token,  4156.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3396.25 ms /    12 tokens (  283.02 ms per token,     3.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19972.38 ms /    40 runs   (  499.31 ms per token,     2.00 tokens per second)\n",
      "llama_print_timings:       total time =   23542.67 ms /    52 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 301 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Business Statistics and Analysis Capstone\n",
      "Prerequisites: ['python','pandas','numpy','matplotlib','seaborn','sklearn','statsmodels','patsy']\n",
      "Learning Outcomes: ['Business Statistics and Analysis Capstone' , 'Statistics and Analysis' , 'Data Analysis and Visualization' , 'Business Analytics' , 'Business Decision Making' , 'Data Interpretation and Presentation']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    24 runs   (    0.27 ms per token,  3738.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   78802.85 ms /   301 tokens (  261.80 ms per token,     3.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11733.83 ms /    23 runs   (  510.17 ms per token,     1.96 tokens per second)\n",
      "llama_print_timings:       total time =   90621.98 ms /   324 tokens\n",
      "Llama.generate: 292 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    25 runs   (    0.27 ms per token,  3756.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4473.34 ms /    12 tokens (  372.78 ms per token,     2.68 tokens per second)\n",
      "llama_print_timings:        eval time =   13091.15 ms /    24 runs   (  545.46 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   17657.29 ms /    36 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 130 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Grab Data Fast with Vertical and Horizontal LOOKUP\n",
      "Prerequisites: ['Introduction to Google Sheets and Google Apps Script', 'Introduction to VLOOKUP and HLOOKUP Formulas']\n",
      "Learning Outcomes: [[\"Ability to extract data using VLOOKUP and HLOOKUP in Excel, Google Sheets or other spreadsheet software\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    48 runs   (    0.23 ms per token,  4412.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27663.71 ms /   130 tokens (  212.80 ms per token,     4.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19773.94 ms /    47 runs   (  420.72 ms per token,     2.38 tokens per second)\n",
      "llama_print_timings:       total time =   47594.07 ms /   177 tokens\n",
      "Llama.generate: 121 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      19.71 ms /   100 runs   (    0.20 ms per token,  5073.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3451.71 ms /    12 tokens (  287.64 ms per token,     3.48 tokens per second)\n",
      "llama_print_timings:        eval time =   37256.76 ms /    99 runs   (  376.33 ms per token,     2.66 tokens per second)\n",
      "llama_print_timings:       total time =   40983.96 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 378 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Global Health: An Interdisciplinary Overview\n",
      "Prerequisites: ```\n",
      "prerequisites = [\"Basic knowledge of statistics\", \"Basic knowledge of epidemiology\", \"Good written and verbal communication skills\", \"Familiarity with global health issues\", \"Undergraduate degree in a field relevant to global health\"]\n",
      "Learning Outcomes: ```\n",
      "[\n",
      "    {\"knowledge\": \"Understand the main global health challenges\"},\n",
      "    {\"knowledge\": \"Appreciate the interdisciplinary nature of global health studies\"},\n",
      "    {\"knowledge\": \"Know the role of global health governance\"},\n",
      "    {\"knowledge\": \"Be familiar with health inequities and inequalities\"},\n",
      "    {\"skills\": \"Apply critical thinking and analytical skills\"},\n",
      "    {\"skills\": \"Develop effective communication skills\"},\n",
      "    {\"skills\": \"Demonstrate leadership and management skills\"},\n",
      "    {\"skills\": \"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    49 runs   (    0.20 ms per token,  5079.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   92504.28 ms /   378 tokens (  244.72 ms per token,     4.09 tokens per second)\n",
      "llama_print_timings:        eval time =   17294.07 ms /    48 runs   (  360.29 ms per token,     2.78 tokens per second)\n",
      "llama_print_timings:       total time =  109933.82 ms /   426 tokens\n",
      "Llama.generate: 369 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    13 runs   (    0.27 ms per token,  3714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2748.78 ms /    12 tokens (  229.06 ms per token,     4.37 tokens per second)\n",
      "llama_print_timings:        eval time =    6301.89 ms /    12 runs   (  525.16 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =    9100.11 ms /    24 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 235 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Python Programming Essentials\n",
      "Prerequisites: [\n",
      "  'basic understanding of programming concepts',\n",
      "  'familiarity with variables, expressions, and conditionals',\n",
      "  'ability to write and run simple Python programs',\n",
      "  'basic knowledge of mathematical concepts, such as modular arithmetic',]\n",
      "Learning Outcomes: ```python\n",
      "[\n",
      "    [\"Basic understanding of Python programming\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    15 runs   (    0.17 ms per token,  5738.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   46034.82 ms /   235 tokens (  195.89 ms per token,     5.10 tokens per second)\n",
      "llama_print_timings:        eval time =    4841.15 ms /    14 runs   (  345.80 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =   50909.94 ms /   249 tokens\n",
      "Llama.generate: 226 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =      19.31 ms /   100 runs   (    0.19 ms per token,  5178.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2223.07 ms /    12 tokens (  185.26 ms per token,     5.40 tokens per second)\n",
      "llama_print_timings:        eval time =   36073.36 ms /    99 runs   (  364.38 ms per token,     2.74 tokens per second)\n",
      "llama_print_timings:       total time =   38577.99 ms /   111 tokens\n",
      "Llama.generate: 4 prefix-match hit, remaining 360 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Creating Dashboards and Storytelling with Tableau\n",
      "Prerequisites: [Data Visualization, Advanced Functions in Tableau, Storytelling Techniques]\n",
      "Learning Outcomes: [{'title': 'Develop dashboards that identify the story within your data', 'description': 'Identify key insights and trends using visualizations, and structure and organize your story for maximum impact'}, \n",
      "{'title': 'Create a compelling narrative to leave a lasting impression', 'description': 'Use Storypoints to create a powerful story, and balance the goals of stakeholders with the needs of end-users'}, \n",
      "{'title': 'Apply advanced functions within Tableau to guide user interactions', 'description]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  108867.63 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /    19 runs   (    0.14 ms per token,  7044.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   80991.58 ms /   360 tokens (  224.98 ms per token,     4.44 tokens per second)\n",
      "llama_print_timings:        eval time =    5881.96 ms /    18 runs   (  326.78 ms per token,     3.06 tokens per second)\n",
      "llama_print_timings:       total time =   86913.26 ms /   378 tokens\n",
      "Llama.generate: 351 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_cpp import Llama\n",
    "import time\n",
    "#Coursera Dataset\n",
    "csv_file_path = r'C:\\Users\\DELL\\Downloads\\Coursera Dataset (2).csv'\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#Columns to take into concideration\n",
    "columns_to_extract = ['Course Name', 'University', 'Difficulty Level', 'Course Rating', 'Course Description', 'Skills']\n",
    "\n",
    "# Path to the model (downloaded from LM studio)\n",
    "model_path = r'C:\\Users\\DELL\\.cache\\lm-studio\\models\\deven367\\Meta-Llama-3.1-8B-Instruct-Q5_K_M-GGUF\\meta-llama-3.1-8b-instruct-q5_k_m.gguf'\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_gpu_layers=-1,  \n",
    "    n_ctx=2048,  \n",
    ")\n",
    "\n",
    "# Function to generate prerequisites for a course\n",
    "def generate_prerequisites(course_description):\n",
    "    prompt = f\"{course_description}\\nLastly, Prerequisites you need to have (written in a python array):\"\n",
    "    \n",
    "    try:\n",
    "        output = llm(\n",
    "            prompt=prompt,\n",
    "            max_tokens=100,\n",
    "            stop=[\"]\"],\n",
    "            echo=False\n",
    "        )\n",
    "        return output['choices'][0]['text'].strip() + \"]\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating prerequisites: {e}\")\n",
    "        return \"[]\"\n",
    "\n",
    "# Function to generate learning outcomes for a course\n",
    "def generate_learning_outcomes(course_description):\n",
    "    prompt = f\"{course_description}\\nLastly, Learning outcomes you will gain (written in a python array):\"\n",
    "    \n",
    "    try:\n",
    "        output = llm(\n",
    "            prompt=prompt,\n",
    "            max_tokens=100,\n",
    "            stop=[\"]\"],\n",
    "            echo=False\n",
    "        )\n",
    "        return output['choices'][0]['text'].strip() + \"]\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating learning outcomes: {e}\")\n",
    "        return \"[]\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#New columns\n",
    "df['Pre-requisite Skills'] = ''\n",
    "df['Learning Outcomes Skills'] = ''\n",
    "\n",
    "# Process in batches to handle large datasets\n",
    "batch_size = 50\n",
    "for start in range(0, len(df), batch_size):\n",
    "    end = min(start + batch_size, len(df))\n",
    "    batch_df = df.iloc[start:end]\n",
    "    \n",
    "    for index, row in batch_df.iterrows():\n",
    "        description = \"\"\n",
    "        course_name = row['Course Name']\n",
    "        for col in columns_to_extract:\n",
    "            description += f\"{col}: {row[col]}\\n\"\n",
    "        \n",
    "        # Generate prerequisites and learning outcomes\n",
    "        prerequisites = generate_prerequisites(description)\n",
    "        learning_outcomes = generate_learning_outcomes(description)\n",
    "        \n",
    "        # Save the generated skills into the DataFrame\n",
    "        df.at[index, 'Pre-requisite Skills'] = prerequisites\n",
    "        df.at[index, 'Learning Outcomes Skills'] = learning_outcomes\n",
    "        \n",
    "        # Print for debugging or progress tracking\n",
    "        print(f\"Course: {course_name}\\nPrerequisites: {prerequisites}\\nLearning Outcomes: {learning_outcomes}\\n\")\n",
    "\n",
    "#New CSV file\n",
    "output_csv_path = r'C:\\Users\\DELL\\Desktop\\Desktop\\Stage\\Results\\Coursera_Dataset_with_Skills1.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Processing time: {time.time() - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11a651d-78ed-49d8-ba0b-9450d9add8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
